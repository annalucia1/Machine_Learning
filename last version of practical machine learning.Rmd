
---
title: "Practical Machine Learning Project"
author: "Anlu Xing"
date: "August 22, 2015"
output: html_document
---


## Introduction

The Weight Lifting Exercises dataset is to investigate "how (well)" an activity was performed by the wearer. Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes. This project used data from accelerometers (devices such as Jawbone Up, Nike FuelBand, and Fitbit) on the belt, forearm, arm, and dumbell of 6 participants to quantify how well they do the weight lifting.


### Set up work directory and load libraries and data
```{r}
setwd("C:/Users/anlu/datasciencecoursera/machine learning")
library(AppliedPredictiveModeling)
library(ggplot2)
library(lattice)
library(caret)
library(rpart)
library(randomForest)
set.seed(123)
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
file_dest_training <- "pml-training.csv"
file_dest_testing <- "pml-testing.csv"
#myTraining<- read.csv(file_dest_training, na.strings=c("NA",""), header=TRUE)
#myTesting <-read.csv(file_dest_testing, na.strings=c("NA",""), header=TRUE)
myTraining <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
myTesting <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
```

## Clean the Data

### Data cleaning for training set

* Remove near zero covariates

```{r}
nsv <- nearZeroVar(myTraining, saveMetrics = T)
myTraining <- myTraining[, !nsv$nzv]
```

* Remove first column of Dataset 

```{r}
myTraining <- myTraining[c(-1)]
```

* Clean Variables with too many NAs


```{r}
nav <- sapply(colnames(myTraining), function(x) if(sum(is.na(myTraining[, x])) > 0.6*nrow(myTraining)){return(T)}else{return(F)})
myTraining <- myTraining[, !nav]
```



## Boosting model

* Fit model with boosting algorithm and 10-fold cross validation to predict `classe` with all other predictors.    

```{r}
#boostFit <- train(classe ~ ., method = "gbm", data = myTraining, verbose = F, trControl = trainControl(method = "cv", number = 10))
```

* Plot accuracy of this model on the scale `[0.9, 1]`.        


```{r boost_plot}
#boostFit
#plot(boostFit, ylim = c(0.9, 1))
```

The accuracy is 0.997.

## Random Forests

```{r}
rfFit <- train(classe ~ ., method = "rf", data =myTraining, importance = T, trControl = trainControl(method = "cv", number = 10))

```

